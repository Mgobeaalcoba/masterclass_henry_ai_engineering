#!/usr/bin/env python
"""
Demostraci√≥n: LLM sin contexto de datos privados

Muestra c√≥mo GPT-4 NO puede responder sobre informaci√≥n privada de empresas
porque no tiene acceso a documentaci√≥n interna.
"""

import os
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()  # Cargar API Key desde archivo .env

def detectar_modelo(client):
    """Detecta qu√© modelo de OpenAI est√° disponible en tu cuenta."""
    for modelo in ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-3.5-turbo"]:
        try:
            client.chat.completions.create(model=modelo, messages=[{"role": "user", "content": "test"}], max_tokens=5)
            return modelo
        except:
            continue
    return None

def main():
    """Chat interactivo con GPT sin contexto - Demuestra la falta de conocimiento sobre datos privados."""
    
    # Verificar API Key
    if not os.getenv("OPENAI_API_KEY"):
        print("‚ùå Error: Configura OPENAI_API_KEY en el archivo .env")
        return
    
    # Inicializar cliente y detectar modelo
    client = OpenAI()
    print("\nüîç Detectando modelo disponible...")
    modelo = detectar_modelo(client)
    
    if not modelo:
        print("‚ùå No se encontr√≥ ning√∫n modelo disponible")
        return
    
    print(f"‚úÖ Usando modelo: {modelo}\n")
    print("="*60)
    print("  üí¨ Chat SIN Contexto - El modelo NO conoce datos privados")
    print("="*60)
    print("\nüí° Escribe 'salir' para terminar\n")
    
    # Prompt del sistema para evitar alucinaciones
    system_prompt = """Eres un asistente honesto y directo. Si no conoces o no tienes informaci√≥n sobre algo, 
debes decir claramente "No s√© sobre..." o "No tengo informaci√≥n sobre..." en lugar de inventar o suponer.
S√© preciso y no inventes detalles que no conoces."""
    
    # Loop de conversaci√≥n
    while True:
        pregunta = input("üßë T√ö: ").strip()
        
        if pregunta.lower() in ['salir', 'exit', 'quit']:
            print("\nüëã ¬°Hasta luego!\n")
            break
        
        if not pregunta:
            continue
        
        # Consultar a GPT con configuraci√≥n anti-alucinaci√≥n
        try:
            print(f"\n‚è≥ Consultando {modelo}...\n")
            respuesta = client.chat.completions.create(
                model=modelo,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": pregunta}
                ],
                temperature=0.1,  # Temperatura muy baja para reducir creatividad y alucinaciones
                max_tokens=500,
                top_p=0.9  # Nucleus sampling m√°s restrictivo
            ).choices[0].message.content
            
            print(f"ü§ñ {modelo.upper()}: {respuesta}\n")
            print("-" * 60 + "\n")
        except Exception as e:
            print(f"‚ùå Error: {e}\n")

if __name__ == "__main__":
    main()
